version: 2.1

orbs:
  aws-cli: circleci/aws-cli@2.0.3
  aws-eks: circleci/aws-eks@1.1.0
  kubernetes: circleci/kubernetes@0.4.0
#commands:
#  destroy-environment:
#    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
#
#    steps:
#      - run:
#          name: Destroy environments
#          when: on_fail
#          command: |
#              #aws s3 rm s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
#              #aws cloudformation delete-stack --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
#
#  revert-migrations:
#    description: Revert the last migration if successfully run in the current workflow.
#
#    steps:
#      - run:
#          name: Revert migrations
#          when: on_fail
#          command: |
#            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
#            SUCCESS=$(curl --insecure  https://kvdb.io/DT8CarpLgRbw4JjJvavCnS/migration_${CIRCLE_WORKFLOW_ID:0:7})
#            if(( $SUCCESS==1 )); 
#            then
#            cd ~/project/backend
#            npm install
#            npm run migrations:revert
#            fi
            
jobs:
  linting:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Run Dockerfile and JS code linting
          command: |
            ls
            pwd
            make all

  build-docker-image:
    working_directory: /myapp
    docker:
      - image: docker:cli
    steps:
      - checkout
      - setup_remote_docker
      - restore_cache:
          keys:
            - v1-{{ .Branch }}
          paths:
            - /caches/myapp.tar
      - run:
          name: Load Docker image layer cache
          command: |
            set +o pipefail
            docker load -i /caches/myapp.tar | true
      - run:
          name: Build docker image
          command: |
            docker build --cache-from=myapp --tag=myapp .
            docker build --tag=myapp .
            docker images
      - run:
          name: Save Docker image layer cache
          command: |
            mkdir -p /caches
            docker save -o /caches/myapp.tar myapp
      - save_cache:
          key: v1-{{ .Branch }}-{{ epoch }}
          paths:
            - /caches/myapp.tar
      #- run:
      #    name: Run docker image
      #    command: |
      #      docker run -dp 3000:3000 myapp
      - run:
          name: Push docker image
          command: |
            docker_path=hieudd
            echo "Docker ID and Image: $docker_path"
            export mypw=hnplhh1008
            echo "$mypw" | docker login -u $docker_path --password-stdin
            docker image tag "myapp:latest" "$docker_path/myapp:${CIRCLE_WORKFLOW_ID:0:7}"
            docker image push "$docker_path/myapp:${CIRCLE_WORKFLOW_ID:0:7}"

#  build-frontend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [frontend-build]
#      - run:
#          name: Build front-end
#          command: |
#            # Your code here
#            cd frontend
#            npm install
#            npm run build
#            # exit 1
#      - save_cache:
#          paths: [frontend/node_modules]
#          key: frontend-build
#
#  build-backend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [backend-build]
#      - run:
#          name: Back-end build
#          command: |
#             # Your code here
#             cd backend
#             npm install
#             npm run build
#             # exit 1
#      - save_cache:
#          paths: [backend/node_modules]
#          key: backend-build
#
#  test-frontend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [frontend-build]
#      - run:
#          name: run frontend tests
#          command: |
#            # Your code here
#            cd frontend
#            npm install
#            npm run test
#  test-backend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [backend-build]
#      - run:
#          name: Run backend tests
#          command: |
#             # Your code here
#             cd backend
#             npm install
#             npm run test
#  scan-frontend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [frontend-build]
#      - run:
#          name: Scan front-end
#          command: |
#            cd frontend
#            npm install
#            # npm install oauth-sign@^0.9.0
#            npm audit fix --force --audit-level=critical
#            # If the "npm audit fix" command above could not fix all critical vulnerabilities, try “npm audit fix --force” again
#            # npm audit --audit-level=critical
#  scan-backend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - restore_cache:
#          keys: [backend-build]
#      - run:
#          name: Scan backend-end
#          command: |
#            cd backend
#            npm install
#            npm audit fix --force --audit-level=critical
#            # If the "npm audit fix" command above could not fix all critical vulnerabilities, try “npm audit fix --force” again
#            # npm audit --audit-level=critical

  deploy-infrastructure:
    #docker:
      #- image: cimg/base:2021.04
    executor: aws-eks/python3
    steps:
      - checkout
      #- run:
      #    name: Install dependencies
      #    command: |
      #      pwd
      #      ls
      #      curl --location "https://github.com/eksctl-io/eksctl/releases/download/v0.150.0/eksctl_Linux_amd64.tar.gz" | tar xzv -C /tmp
      #      sudo chown -R $(whoami) /usr/local/bin
      #      sudo mv /tmp/eksctl /usr/local/bin

      #      curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
      #      unzip awscliv2.zip
      #      sudo ./aws/install
      #- run:
      #    name: Check aws
      #    command: |
      #       pwd
      #       ls
      #       whoami
      #       aws configure list
      #       aws cloudformation list-stacks
      #       aws iam list-users
      #       eksctl create cluster --region us-east-1 --name aws-k8s-cluster --nodegroup-name aws-k8s-cluster --instance-types=t2.micro --nodes 2 --ssh-access --ssh-public-key udacity-project5 --managed
      - aws-eks/install-aws-iam-authenticator:
          release-tag: ''
      - aws-eks/create-cluster:
          cluster-name: k8s-project5-${CIRCLE_WORKFLOW_ID:0:7}
          install-kubectl: true
          verbose: 3
          node-type: t2.micro
          nodes-max: 2
          ssh-access: false
          ssh-public-key: ''

  create-service:


#          name: Ensure back-end infrastructure exists
#          command: |
#            aws cloudformation deploy \
#              --template-file .circleci/files/backend.yml \
#              --tags Project=uda-people \
#              --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
#              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7}
#              # exit 1
#      - run:
#          name: Ensure front-end infrastructure exist
#          command: |
#            aws cloudformation deploy \
#              --template-file .circleci/files/frontend.yml \
#              --tags Project=uda-people \
#              --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7} \
#              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7}  
#              # exit 1
#      - run:
#          name: Add back-end ip to ansible inventory
#          command: |
#            # Your code here
#            aws ec2 describe-instances --query 'Reservations[*].Instances[*].{Instance:PublicIpAddress}' --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --output text >> .circleci/ansible/inventory.txt
#            cat .circleci/ansible/inventory.txt
#            # exit 1
#      - persist_to_workspace:
#          root: .circleci
#          paths:
#            - ansible/inventory.txt
#      # Here's where you will add some code to rollback on failure     
#      - destroy-environment

  configure-infrastructure:
    #docker:
    #  - image: python:3.7-alpine3.11
    #steps:
    #  - checkout
    executor: aws-eks/python3
    steps:
      - checkout
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: k8s-project5-${CIRCLE_WORKFLOW_ID:0:7}
          install-kubectl: true
      - kubernetes/create-or-update-resource:
          resource-file-path: k8s-services.yml
          resource-name: service/k8s-project5-LoadBalancer
#      - add_ssh_keys:
#          fingerprints: ["09:98:3b:1d:61:bf:45:a4:56:92:a4:c2:7d:7e:13:63"]
#      - attach_workspace:
#          at: .circleci/
#      - run:
#          name: Install dependencies
#          command: |
#            # Your code here
#            apk add --update ansible 
#            #exit 1
#      - run:
#          name: Configure server
#          command: |
#            # Your code here
#            echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> backend/.env
#            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> backend/.env
#            echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> backend/.env
#            echo TYPEORM_HOST=$TYPEORM_HOST >> backend/.env
#            echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> backend/.env
#            echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> backend/.env
#            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> backend/.env
#            echo TYPEORM_PORT=$TYPEORM_PORT >> backend/.env
#            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> backend/.env
#            cat backend/.env
#            ansible-playbook -i .circleci/ansible/inventory.txt .circleci/ansible/configure-server.yml
#            cat .circleci/ansible/inventory.txt
#            #exit 1
#      # Here's where you will add some code to rollback on failure
#      - destroy-environment

#  run-migrations:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - run:
#          name: Run migrations
#          command: |
#            # Your code here
#            cd backend
#            npm install
#            ## Run and save the migration output
#            npm run migrations > migrations_dump.txt
#            cat migrations_dump.txt
#            #exit 1
#      - run:
#          name: Send migration results to kvdb.io
#          command: |
#            # Your code here
#            pwd
#            ls
#            if grep -q "No migrations are pending" ~/project/backend/migrations_dump.txt
#            then
#            API_KVDB_URL="https://kvdb.io/DT8CarpLgRbw4JjJvavCnS/migration_${CIRCLE_WORKFLOW_ID:0:7}"
#            echo ${API_KVDB_URL}
#            curl --insecure ${API_KVDB_URL} -d '1'
#            fi
#            #exit 1
#      # Here's where you will add some code to rollback on failure
#      - revert-migrations#

#  deploy-frontend:
#    docker:
#      - image: circleci/node:13.8.0
#    steps:
#      - checkout
#      - run:
#          name: Install dependencies
#          command: |
#            # your code here
#            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#            unzip awscliv2.zip
#            sudo ./aws/install
#      - run:
#          name: Get backend url
#          command: |
#            # your code here
#            export BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].{Instance:PublicIpAddress}' --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --output text)
#            export API_URL="http://${BACKEND_IP}:3030"
#            echo "API_URL = ${API_URL}"
#            echo API_URL="http://${BACKEND_IP}:3030" >> frontend/.env
#            cat frontend/.env
#      - run:
#          name: Deploy frontend objects
#          command: |
#            # your code here
#            cd frontend
#            npm install
#            npm run build
#            tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz dist
#            aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
#      # Here's where you will add some code to rollback on failure      
#      - destroy-environment
#  deploy-backend:
#    docker:
#      - image: python:3.7-alpine3.11
#    steps:
#      - checkout
#      - add_ssh_keys:
#          fingerprints: ["09:98:3b:1d:61:bf:45:a4:56:92:a4:c2:7d:7e:13:63"]
#      - attach_workspace:
#          at: .circleci/
#      - run:
#          name: Install dependencies
#          command: |
#            # your code here
#            apk add --update ansible
#            apk add --update npm
#      - run:
#          name: Deploy backend
#          command: |
#            # your code here
#            cd backend
#            npm i
#            npm run build
#            cd ..
#            ## Zip the directory
#            tar -C backend -czvf artifact-backend.tar.gz .
#            ls
#            pwd
#            mkdir .circleci/ansible/roles/deploy/files
#            mv artifact-backend.tar.gz .circleci/ansible/roles/deploy/files
#            cd .circleci/ansible
#            echo "Contents  of the inventory.txt file is -------"
#            cat inventory.txt
#            ansible-playbook -i inventory.txt deploy-backend.yml
#      # Here's where you will add some code to rollback on failure  
#      - destroy-environment

  create-deployment:
    executor: aws-eks/python3
    steps:
      - checkout
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: k8s-project5-${CIRCLE_WORKFLOW_ID:0:7}
          install-kubectl: true
      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: k8s-deployment.yml
          resource-name: deployment/myapp-project5

  smoke-test:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
#      - run:
#          name: Install dependencies
#          command: |
#            # your code here
#            #apk add --update curl
#            #apk add --update sudo
#            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
#            unzip awscliv2.zip
#            sudo ./aws/install
#      - run:
#          name: Get backend url
#          command: |
#            # your code here
#            aws --version
#            /usr/local/bin/aws --version
#            echo "BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].{Instance:PublicIpAddress}' --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --output text)"
#      - run:
#          name: Backend smoke test.
#          command: |
#            # your code here
#            export BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].{Instance:PublicIpAddress}' --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" --output text)
#            export API_URL="http://${BACKEND_IP}:3030/api/status"
#            echo "API_URL = ${API_URL}"
#            export BACKEND_RESPONSE=$(curl ${API_URL})
#            if [[ $BACKEND_RESPONSE == *"ok"* ]] 
#            then
#            	exit 0
#            else
#            	exit 1
#            fi
#      - run:
#          name: Frontend smoke test.
#          command: |
#            # your code here
#            URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com/#/employees"            
#            echo ${URL}
#            export FRONT_RESPONSE=$(curl -s ${URL})
#            if [[ $FRONT_RESPONSE == *"Welcome"* ]] 
#            then
#            	# Change this to 0 after the job fails
#              exit 0
#            else
#              exit 1
#            fi
#      # Here's where you will add some code to rollback on failure  
#      - destroy-environment
#      - revert-migrations
  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
#      - run:
#          name: Install dependencies
#          command: |
#            # your code here
#      - run:
#          name: Update cloudfront distribution
#          command: |
#            # your code here
#            export oldWorkflowID=$(aws cloudformation list-exports --query "Exports[?Name==\`WorkflowID\`].Value" --no-paginate --output text)
#            echo $oldWorkflowID >> ~/oldWorkflowID.txt
#            cat ~/oldWorkflowID.txt
#            aws cloudformation deploy --template-file .circleci/files/cloudfront.yml --stack-name udapeople-cloudfront --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" oldWorkflowID="$oldWorkflowID" --tags Project=uda-people
#            echo oldWorkflowID: "${oldWorkflowID}"
#            echo currentWorkflowID: "${CIRCLE_WORKFLOW_ID:0:7}"
#      # Here's where you will add some code to rollback on failure  
#      - destroy-environment
  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name:
          command: |
            exit 1
#      - run:
#          name: Get old stack workflow id and clean up follow blue green deployment
#          command: |
#            # your code here
#            ## Fetch the Old workflow ID
#            export OldWorkflowID=$(aws cloudformation list-exports --query "Exports[?Name==\`oldWorkflowID\`].Value" --no-paginate --output text)
#            echo OldWorkflowID: "${OldWorkflowID}"
#            echo CIRCLE_WORKFLOW_ID "${CIRCLE_WORKFLOW_ID:0:7}"
#            ## Fetch the stack names         
#            export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" --stack-status-filter CREATE_COMPLETE --no-paginate --output text)) 
#            echo Stack names: "${STACKS[@]}"
#            if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
#            then
#              # your code here
#              echo "--------------------------------Deleting Stacks----------------------------------------------"
#              aws s3 rm "s3://udapeople-${OldWorkflowID}" --recursive
#              aws cloudformation delete-stack --stack-name "udapeople-backend-${OldWorkflowID}"
#              aws cloudformation delete-stack --stack-name "udapeople-frontend-${OldWorkflowID}"
#              aws cloudformation delete-stack --stack-name "cloudfront-${OldWorkflowID}"
#            else
#              echo "--------------------------------Cannot Delete Stacks----------------------------------------------"
#            fi
            
workflows:
  default:
    jobs:
      #- linting
      #- build-docker-image:
      #    requires: [linting]
      #    filters:
      #      branches:
      #        only: [main]
      - deploy-infrastructure:
      #    requires: [build-docker-image]
          filters:
            branches:
              only: [main]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
          filters:
            branches:
              only: [main]
      - create-deployment:
          requires: [configure-infrastructure]
          filters:
            branches:
              only: [main]
      - smoke-test:
          requires: [configure-infrastructure]
          filters:
            branches:
              only: [master]
      - cloudfront-update:
          requires: [smoke-test]
          filters:
            branches:
              only: [master]
      - cleanup:
          requires: [cloudfront-update]
          filters:
            branches:
              only: [master]