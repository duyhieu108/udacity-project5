version: 2.1

orbs:
  aws-cli: circleci/aws-cli@2.0.3
  aws-eks: circleci/aws-eks@1.1.0
  kubernetes: circleci/kubernetes@1.3
#commands:
#  destroy-environment:
#    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
#
#    steps:
#      - run:
#          name: Destroy environments
#          when: on_fail
#          command: |
#              #aws s3 rm s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
#              #aws cloudformation delete-stack --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
#
#  revert-migrations:
#    description: Revert the last migration if successfully run in the current workflow.
#
#    steps:
#      - run:
#          name: Revert migrations
#          when: on_fail
#          command: |
#            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
#            SUCCESS=$(curl --insecure  https://kvdb.io/DT8CarpLgRbw4JjJvavCnS/migration_${CIRCLE_WORKFLOW_ID:0:7})
#            if(( $SUCCESS==1 )); 
#            then
#            cd ~/project/backend
#            npm install
#            npm run migrations:revert
#            fi
            
jobs:
  linting:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Run Dockerfile and JS code linting
          command: |
            ls
            pwd
            make all

  build-docker-image:
    working_directory: /myapp
    docker:
      - image: docker:cli
    steps:
      - checkout
      - setup_remote_docker
      - restore_cache:
          keys:
            - v1-{{ .Branch }}
          paths:
            - /caches/myapp.tar
      - run:
          name: Load Docker image layer cache
          command: |
            set +o pipefail
            docker load -i /caches/myapp.tar | true
      - run:
          name: Build docker image
          command: |
            docker build --cache-from=myapp --tag=myapp .
            docker build --tag=myapp .
            docker images
      - run:
          name: Save Docker image layer cache
          command: |
            mkdir -p /caches
            docker save -o /caches/myapp.tar myapp
      - save_cache:
          key: v1-{{ .Branch }}-{{ epoch }}
          paths:
            - /caches/myapp.tar
      #- run:
      #    name: Run docker image
      #    command: |
      #      docker run -dp 3000:3000 myapp
      - run:
          name: Push docker image
          command: |
            docker_path=hieudd
            echo "Docker ID and Image: $docker_path"
            export mypw=hnplhh1008
            echo "$mypw" | docker login -u $docker_path --password-stdin
            docker image tag "myapp:latest" "$docker_path/myapp:${CIRCLE_WORKFLOW_ID:0:7}"
            docker image push "$docker_path/myapp:${CIRCLE_WORKFLOW_ID:0:7}"

  deploy-infrastructure:
    docker:
      - image: cimg/base:2021.04
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pwd
            ls
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install

            curl --location "https://github.com/eksctl-io/eksctl/releases/download/v0.150.0/eksctl_Linux_amd64.tar.gz" | tar xzv -C /tmp
            sudo chown -R $(whoami) /usr/local/bin
            sudo mv /tmp/eksctl /usr/local/bin

      - run:
          name: Check aws/eks installed
          command: |
            pwd
            ls
            whoami
            aws configure list
            aws iam list-users
            eksctl version

      - run:
          name: create k8s cluster
          command: |
            eksctl create cluster --region us-east-2 --name k8s-project5 --nodegroup-name k8s-project5 --instance-types=t2.micro --nodes 2 --managed
            aws eks update-kubeconfig --region us-east-2 --name k8s-project5

  configure-infrastructure:
    executor: aws-eks/python3
    steps:
      - checkout
      - run:
          command: |
            pwd
            whoami
            ls
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: k8s-project5
          install-kubectl: true
      - kubernetes/create-or-update-resource:
          resource-file-path: k8s-services.yml
          resource-name: service/k8s-project5-loadbalancer

  create-deployment:
    executor: aws-eks/python3
    #docker:
    #  - image: cimg/base:2021.04
    steps:
      - checkout
      - kubernetes/install-kubectl
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: k8s-project5
          install-kubectl: true
      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: k8s-deployment.yml
          resource-name: deployment/myapp
          show-kubectl-command: true
      - run:
          name: check cluster details
          command: |
            kubectl get nodes
            kubectl get deploy,rs,svc,pods

workflows:
  default:
    jobs:
      #- linting
      #- build-docker-image:
      #    requires: [linting]
      #    filters:
      #      branches:
      #        only: [main]
      - deploy-infrastructure:
      #    requires: [build-docker-image]
          filters:
            branches:
              only: [main]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
          filters:
            branches:
              only: [main]
      - create-deployment:
          requires: [configure-infrastructure]
          filters:
            branches:
              only: [main]
      - aws-eks/update-container-image:
          requires: [create-deployment]
          filters:
            branches:
              only: [main]
          cluster-name: nginxcustomcluster1
          container-image-updates: "myapp=hieudd/myapp:5dbc4cf"
          resource-name: deployment/myapp